**HNSWLib vs FAISS. Поиска по эмбеддингам для системы video-rag**

**Сравнительный анализ производительности HNSWLib и FAISS на различных объемах данных**

Современные задачи поиска сходства, особенно в области машинного обучения и обработки больших объемов данных, требуют выбора подходящей библиотеки для реализации решений. В контексте сравнения скорости поиска между HNSWLib и FAISS значимым становится учет их архитектурных различий и зависимостей от аппаратных

возможностей. HNSWLib демонстрирует превосходную производительность на CPU при работе с малыми и средними датасетами благодаря графовой [структуре ](https://zilliz.com/blog/faiss-vs-hnswlib-choosing-the-right-tool-for-vector-search)[[10](https://zilliz.com/blog/faiss-vs-hnswlib-choosing-the-right-tool-for-vector-search)]. Эта структура минимизирует количество сравнений за счет навигации между узлами, что делает алгоритм особенно эффективным для реального времени приложений, где задержки должны быть минимальны. Например, при работе с наборами данных до 100 тысяч векторов HNSWLib обеспечивает recall около 0.9 без необходимости сложной настройки параметров[ \[6](https://stackoverflow.com/questions/65379421/hnswlib-parameters-for-large-datasets)].

Однако при переходе к миллионам векторов требуется тщательная оптимизация параметров M и ef\_construction для поддержания высокой точности. Эксперименты показывают, что увеличение ef\_construction до значений выше 1000 может потребовать также увеличения M для поддержания производительности на уровне recall ≥ 0.95[ \[6](https://stackoverflow.com/questions/65379421/hnswlib-parameters-for-large-datasets)]. Несмотря на это, время построения индекса значительно возрастает с ростом этих параметров, достигая нескольких часов для наборов данных размером более 1 миллиона векторов [\[6](https://stackoverflow.com/questions/65379421/hnswlib-parameters-for-large-datasets)].

Когда речь идет о больших объемах данных (например, более 37 миллионов векторов), производительность HNSWLib начинает снижаться. Исследования показывают, что время выполнения запросов увеличивается в 2–3 раза по сравнению с более компактными наборами данных [ [14](https://github.com/facebookresearch/faiss/issues/2490)]. Это связано с ограничениями оперативной памяти и доминированием системных потоков ядра (kernel threads) при работе с большими массивами данных. Проблема была частично решена путем включения Transparent Hugepage Support (THP) в режиме 'always', что увеличило скорость примерно на 1.5[x \[14](https://github.com/facebookresearch/faiss/issues/2490)]. Тем не менее, даже после этой оптимизации наблюдались колебания использования памяти, указывающие на возможные проблемы с доступом к памяти.

Таким образом, HNSWLib сталкивается с существенными трудностями при работе с очень большими наборами данных, особенно если они превышают доступные ресурсы RAM[ \[10](https://zilliz.com/blog/faiss-vs-hnswlib-choosing-the-right-tool-for-vector-search)]. Оптимизация параметров M и ef\_construction играет важную роль в повышении производительности HNSWLib для больших наборов данных. Исследования рекомендуют начинать с параметров M=16 и ef\_construction=200 как отправной точки для тестирования. Эти значения могут быть скорректированы в зависимости от требуемого уровня точности (recall). Например, для достижения приемлемой точности (хотя бы 0.5) на наборе данных размером 80 миллионов документов потребовалось увеличить параметр M до [400](https://github.com/nmslib/hnswlib/issues/164) [[9](https://github.com/nmslib/hnswlib/issues/164)]. Однако для меньших наборов данных достаточно было значений M в диапазоне от 6 до 48. Это подчеркивает необходимость проведения экспериментов для каждого конкретного случая, чтобы найти баланс между производительностью и точностью[ \[9](https://github.com/nmslib/hnswlib/issues/164)].

Библиотека FAISS особенно эффективна для работы с большими наборами данных,

достигая миллиардов векторов, благодаря поддержке [GPU \[18](https://www.langchain.ca/blog/mastering-faiss-the-ultimate-user-guide/)]. Параметр nprobe позволяет регулировать точность поиска, предоставляя разработчикам возможность настройки под конкретные задачи. Поддержка GPU в FAISS значительно ускоряет процесс поиска, особенно для задач, требующих обработки миллиардов векторов. Например, использование GPU может сократить задержки до менее 20 мс при работе с индексами размером более 10 миллионов векторов [\[18](https://www.langchain.ca/blog/mastering-faiss-the-ultimate-user-guide/)]. Масштабируемость FAISS обеспечивается за счет использования GPU и различных техник квантования, таких как IVF и PQ, что позволяет эффективно работать с огромными объемами данных [\[10](https://zilliz.com/blog/faiss-vs-hnswlib-choosing-the-right-tool-for-vector-search)]. При этом HNSWLib ограничен объемом доступной оперативной памяти, что затрудняет его применение для больших наборов данных.

**Ограничения HNSWLib и FAISS в обработке больших объемов данных**

HNSWLib, известная своей эффективностью при работе с небольшими и средними наборами данных, сталкивается с заметными ограничениями при обращении к большим массивам информации. Одной из ключевых причин этого является необходимость хранения всех данных в оперативной памяти (RAM), что существенно ограничивает масштабируемость инструмента [\[25](https://esteininger.medium.com/building-a-vector-search-engine-using-hnsw-and-cosine-similarity-753fb5268839)]. Например, даже при использовании рекомендуемых параметров, таких

как ef\_construction=200 и M=16 для модели 'all-MiniLM-L6-v2', максимальный размер индекса ограничен доступным объемом RAM. При этом увеличение количества элементов в индексе приводит к повышению требований к памяти, что делает HNSWLib непригодным для работы с датасетами, превышающими возможности аппаратного обеспечения.

Производительность HNSWLib также снижается при работе с очень большими и высокоразмерными данными. Исследования показывают, что на наборах данных размером 6 миллионов документов с параметрами M=300 и efConstruction=400 точность поиска значительно ухудшается, даже при увеличении efSearch до 1600 (до [80.8%) ](https://github.com/nmslib/hnswlib/issues/164)[[9](https://github.com/nmslib/hnswlib/issues/164)]. Проблемы возникают не только из-за высокой размерности данных, но и вследствие наличия множества похожих или дублирующихся документов, которые усложняют процесс

поиска. Для достижения приемлемой точности на датасете размером 80 миллионов документов потребовалось увеличить параметр M до 400, тогда как для меньших наборов достаточно было значений M от 6 до 48. Это подчеркивает зависимость производительности HNSWLib от структуры и объема данных, а также необходимость тщательной предварительной обработки данных для удаления дубликатов или объединения похожих элементов.

В отличие от HNSWLib, FAISS предоставляет более широкие возможности для работы с большими объемами данных за счет использования GPU и методов квантования, таких как IVF (инвертированный файловый индекс) и PQ (квантизация произведения[) \[10](https://zilliz.com/blog/faiss-vs-hnswlib-choosing-the-right-tool-for-vector-search), [19](https://engineering.fb.com/2017/03/29/data-infrastructure/faiss-a-library-for-efficient-similarity-search/)]. Эти методы позволяют эффективно сжимать данные и уменьшать использование памяти, что особенно важно при работе с миллиардами векторов. Например, на датасете Deep1B,

содержащем миллиард 128-мерных векторов, FAISS достиг точности 40% при времени запроса менее 2 мс на один вектор, используя четыре GPU Nvidia Titan [X \[19](https://engineering.fb.com/2017/03/29/data-infrastructure/faiss-a-library-for-efficient-similarity-search/)]. Поддержка GPU позволяет FAISS строить k-NN графы на больших наборах данных за считанные часы, что значительно ускоряет процесс по сравнению с CPU-ориентированными решениями.

Преимущества FAISS также заключаются в гибкости его индексации через IVF и PQ, что обеспечивает возможность настройки баланса между скоростью и точностью поиска. Параметр nprobe позволяет регулировать точность поиска, предоставляя разработчикам контроль над производительностью системы[ \[11](https://zilliz.com/blog/faiss-vs-scann-choosing-the-right-tool-for-vector-search)]. Например, настройка IVF-PQ может быть полезна для оптимизации производительности при работе с датасетами размером более 1 миллиона векторов, а использование GPU для обучения индексов может значительно сократить время подготовки данных. Однако стоит отметить, что внедрение GPU увеличивает стоимость аппаратного обеспечения, что необходимо учитывать при выборе решения.

Таким образом, хотя HNSWLib остается превосходным выбором для задач реального времени с небольшими и средними наборами данных благодаря своей графовой архитектуре и высокой скорости на CPU, его ограничения в плане использования RAM и сложности работы с большими объемами данных делают его менее подходящим для крупномасштабных проектов. В то же время FAISS демонстрирует значительную масштабируемость и гибкость благодаря поддержке GPU и продвинутым методам индексации, таким как IVF и PQ. Поэтому для задач, требующих обработки огромных объемов данных, предпочтение следует отдавать FAISS.

**Сравнительный анализ масштабируемости решений HNSWLib и FAISS**

Масштабируемость является ключевым фактором при выборе библиотек для работы с большими наборами данных, особенно в таких областях, как рекомендательные системы или классификация изображений. В контексте этой задачи рассмотрим две популярные библиотеки: HNSWLib и FAISS. Обе предлагают свои уникальные подходы к оптимизации производительности, но их возможности существенно различаются при работе с динамическими данными и крупномасштабными проектами.

**Возможности HNSWLib для горизонтального масштабирования**

HNSWLib демонстрирует высокую скорость поиска на небольших и средних наборах данных благодаря своей графовой архитектуре, которая минимизирует количество сравнений за счет навигации между [узлами \[10](https://zilliz.com/blog/faiss-vs-hnswlib-choosing-the-right-tool-for-vector-search)]. Однако его эффективность снижается при работе с высокоразмерными данными из-за ограничений оперативной памяти, так как все операции выполняются в RAM. Это делает HNSWLib менее применимым для больших динамических наборов данных, где требуется частое добавление новых элементов или удаление старых записей. Например, удаление данных в HNSW часто приводит к фрагментации графа, что снижает эффективность поиска[ \[15](https://medium.com/data-science/not-all-hnsw-indices-are-made-equaly-6bc0d7efd8c7)].

Для минимизации простоев системы при обновлении данных HNSWLib предлагает методы перестроения индексов, такие как создание резервных копий индексов во время выполнения операций модификации. Тем не менее, это требует значительного объема памяти, что становится критическим ограничением для больших наборов данных [[15](https://medium.com/data-science/not-all-hnsw-indices-are-made-equaly-6bc0d7efd8c7)]. Авторы исследований также предлагают использовать параллельную обработку для ускорения построения индексов, хотя этот процесс зависит от доступности достаточного количества ядер CPU [\[15](https://medium.com/data-science/not-all-hnsw-indices-are-made-equaly-6bc0d7efd8c7)].

**Стратегии FAISS для масштабирования**

В отличие от HNSWLib, FAISS предлагает более гибкие стратегии масштабирования, такие как шардирование и использование распределенных файловых систем [ [8](https://arxiv.org/html/2401.08281v3)]. Библиотека поддерживает различные техники сжатия векторов, такие как инвертированные файловые индексы (IVF) и продуктовая квантизация (PQ), что позволяет эффективно работать с огромными объемами данных [[8](https://arxiv.org/html/2401.08281v3)]. Например, для индексации 1.5 триллионов векторов в 144 измерениях используется комбинация HNSW-квантизатора с 10 миллионами центроидов и IndexIVFScalarQuantizer. Этот процесс разделяется на три этапа: шардирование по ID, шардирование по спискам и загрузка шардов через распределенную файловую систему, что значительно упрощает управление большими массивами данных [\[8](https://arxiv.org/html/2401.08281v3)].

FAISS также демонстрирует выдающуюся производительность при работе с миллиардами векторов благодаря поддержке GPU. Например, на датасете Deep1B с миллиардом изображений FAISS достигает точности 40% при времени запроса менее 2 мс на один вектор, что значительно быстрее предыдущих решений [[19](https://engineering.fb.com/2017/03/29/data-infrastructure/faiss-a-library-for-efficient-similarity-search/)]. На тестах с датасетом Deep1B, содержащим миллиард 128-мерных векторов, FAISS показал возможность построения k-NN графа с точностью 0.65 за менее чем 12 часов на четырёх GPU Nvidia Titan X[ \[19](https://engineering.fb.com/2017/03/29/data-infrastructure/faiss-a-library-for-efficient-similarity-search/)]. Такие результаты подтверждают масштабируемость FAISS для работы с огромными объёмами данных и его способность использовать GPU для значительного ускорения процесса поиска.

**Примеры успешных проектов с использованием FAISS**

Одним из примеров успешного применения FAISS является проект по построению k-NN графов для датасета YFCC100M, который содержит 95 миллионов изображений. Использование восьми GPU Pascal P100 позволило достичь точности 0.8 за 35 минут, что подчеркивает важность аппаратного ускорения для обработки больших объёмов данных [[19](https://engineering.fb.com/2017/03/29/data-infrastructure/faiss-a-library-for-efficient-similarity-search/)]. Другой пример — использование FAISS для хранения индексов в облачных репозиториях, таких как Hugging Face Hub, что упрощает управление большими наборами данных и обеспечивает высокую производительность даже при ограниченных ресурсах [[19](https://engineering.fb.com/2017/03/29/data-infrastructure/faiss-a-library-for-efficient-similarity-search/)].

**Роль аппаратного обеспечения**

Аппаратное обеспечение играет ключевую роль в достижении высокой производительности при работе с большими объемами данных. FAISS предоставляет гибкие возможности для работы с GPU, особенно для задач, где требуется высокая пропускная способность. Алгоритмы оптимизированы для параллельного выполнения на современных GPU, таких как Nvidia A100, которые обеспечивают до 19.5 терафлопс вычислительной [мощности](https://arxiv.org/html/2401.08281v3) [[8](https://arxiv.org/html/2401.08281v3)]. В

то же время, внедрение GPU увеличивает стоимость аппаратного обеспечения, что необходимо учитывать при выборе решения. Для задач, где важна низкая задержка без использования GPU, HNSWLib сохраняет свою привлекательность [\[10](https://zilliz.com/blog/faiss-vs-hnswlib-choosing-the-right-tool-for-vector-search)].

Таким образом, выбор между HNSWLib и FAISS зависит от конкретных требований проекта, включая размер данных, доступные аппаратные ресурсы и необходимость поддержки динамических изменений. FAISS демонстрирует лучшую масштабируемость и гибкость для работы с большими наборами данных, тогда как HNSWLib остается предпочтительным вариантом для задач реального времени с ограниченными объемами памяти.

**Поддержка мультимодальных данных в HNSWLib и FAISS: сравнительный анализ и практические применения**

В современных задачах обработки больших объемов данных, особенно в таких

областях, как рекомендательные системы и медицинская диагностика, возникает необходимость работы с мультимодальными данными. Это требует использования эффективных методов поиска ближайших соседей среди разнородных типов информации, таких как текст, изображения, аудио и другие модальности. В данной работе рассматривается поддержка мультимодальных данных двумя популярными библиотеками — HNSWLib и FAISS, уделяя особое внимание их совместимости с моделями CLIP и ImageBind [\[2](https://medium.com/supportvectors/embedding-multi-modal-data-with-imagebind-3acc0780be7f)].

HNSWLib представляет собой высокоэффективную структуру данных для приближенного поиска ближайших соседей (Approximate Nearest Neighbor Search), которая работает исключительно в оперативной памяти. Однако для работы с мультимодальными эмбеддингами, такими как те, что генерируются моделью ImageBind, требуется дополнительная интеграция. ImageBind создает унифицированные эмбеддинги для шести различных модальностей, объединяя данные через изображения как общий фактор[ \[2](https://medium.com/supportvectors/embedding-multi-modal-data-with-imagebind-3acc0780be7f)]. Хотя HNSWLib демонстрирует высокую производительность на небольших и средних наборах данных, его использование с мультимодальными эмбеддингами может быть ограничено вычислительными ресурсами, особенно при работе с большими массивами данных[ \[4](https://huggingface.co/learn/cookbook/en/faiss_with_hf_datasets_and_clip)].

В отличие от HNSWLib, FAISS предоставляет более широкие возможности для работы с мультимодальными данными благодаря своей масштабируемости и гибкости. Интеграция FAISS с CLIP позволяет строить высокоэффективные решения для поиска по комбинированным текстовым и визуальным запросам. Например, система может принимать текстовый запрос, такой как "человек на водном мотоцикле", и находить соответствующие изображения за короткое время, используя GPU-[ускорение ](https://docs.ultralytics.com/it/%5C/guides/similarity-search/)[[3](https://docs.ultralytics.com/it/%5C/guides/similarity-search/)]. Библиотека Ultralytics упрощает эту интеграцию, предоставляя удобный интерфейс для работы как на CPU, так и на GPU. Такая функциональность делает FAISS особенно подходящим для задач, требующих быстрой реакции на пользовательские запросы.

Примеры применения FAISS в реальных проектах подтверждают его универсальность. Рекомендательные системы, такие как Netflix и Amazon, используют FAISS для поиска похожих элементов в высокоразмерных данных [21[\]. В](https://www.pingcap.com/article/mastering-faiss-vector-database-a-beginners-handbook/) медицинской диагностике FAISS успешно применяется для анализа медицинских изображений и других типов данных,

обеспечивая точность и скорость обработки. Однако важно отметить, что производительность CLIP в сочетании с FAISS снижается при работе с out-of-distribution данными, например, когда запросы не соответствуют распределению данных, на которых модель была обучена[ \[5](https://medium.com/data-science/building-an-image-similarity-search-engine-with-faiss-and-clip-2211126d08fa)]. Для улучшения точности могут потребоваться дополнительные техники оптимизации, такие как дообучение модели или использование специализированных архитектур, таких как OpenCLIP.

Ограничения CLIP также проявляются в контексте тонких классификаций и естественных предвзятостей данных, на которых она была обучена. Например, поиск по изображению картины с глазами может вернуть объекты с похожей геометрией, но не обязательно семантически связанные. Эти ограничения подчеркивают необходимость дальнейших исследований в области мультимодальной обработки данных и совершенствования существующих моделей [[5](https://medium.com/data-science/building-an-image-similarity-search-engine-with-faiss-and-clip-2211126d08fa)].

Заключая, можно сказать, что FAISS предлагает больше возможностей для работы с мультимодальными данными по сравнению с HNSWLib. Его способность обрабатывать большие объемы данных, поддержка GPU-ускорения и гибкость в интеграции с различными моделями, такими как CLIP, делают его предпочтительным выбором для многих практических задач. Тем не менее, для достижения максимальной производительности и точности рекомендуется учитывать ограничения текущих подходов и исследовать новые методы оптимизации.

**Оптимизация производительности GPU в библиотеках HNSWLib и FAISS для задач поиска соседей**

Использование графических процессоров (GPU) играет ключевую роль в оптимизации производительности современных библиотек для приближенного поиска ближайших соседей, таких как FAISS. Однако не все библиотеки поддерживают данную функциональность, что создает различия в их применимости для работы с большими наборами данных. Например, HNSWLib, являясь эффективным инструментом для небольших и средних наборов данных, не имеет поддержки GPU [10[\]. ](https://zilliz.com/blog/faiss-vs-hnswlib-choosing-the-right-tool-for-vector-search)Это ограничение делает его менее подходящим для высокоразмерных задач или больших массивов

данных, которые превышают доступный объем оперативной памяти. В условиях, когда данные не помещаются в RAM, производительность HNSWLib значительно снижается, что затрудняет его использование для крупномасштабных проектов[ \[10](https://zilliz.com/blog/faiss-vs-hnswlib-choosing-the-right-tool-for-vector-search)]. Таким образом, отсутствие поддержки GPU становится критическим фактором, влияющим на масштабируемость HNSWLib и ограничивающим его применимость для задач реального времени с большими данными.

В отличие от HNSWLib, библиотека FAISS предлагает широкие возможности для использования GPU, что существенно ускоряет построение индексов и выполнение запросов. Благодаря применению SIMD-оптимизаций и CUDA, FAISS способен достичь значительного ускорения при работе с миллиардами векторов. Например, тесты показывают, что на датасете Deep1B, содержащем миллиард 128-мерных векторов, FAISS достигает точности 40% при времени запроса менее 2 мс на один вектор[ \[19](https://engineering.fb.com/2017/03/29/data-infrastructure/faiss-a-library-for-efficient-similarity-search/)]. Дополнительно, использование четырех GPU Nvidia Titan X позволило построить k-NN граф с точностью 0.65 за менее чем 12 часов, а при использовании восьми GPU Pascal P100 этот показатель увеличился до 0.8[ \[19](https://engineering.fb.com/2017/03/29/data-infrastructure/faiss-a-library-for-efficient-similarity-search/)]. Такие результаты демонстрируют важность аппаратного ускорения для обработки больших объемов данных и подчеркивают преимущество FAISS перед решениями, работающими исключительно на CPU.

Для эффективного управления ресурсами GPU FAISS использует методы сжатия данных, такие как Product Quantization (PQ), которые позволяют минимизировать использование видеопамяти без значительной потери точности поиска[ \[21](https://www.pingcap.com/article/mastering-faiss-vector-database-a-beginners-handbook/)]. PQ разделяет векторы на подвекторы, каждый из которых кодируется с использованием меньшего количества бит, что значительно уменьшает занимаемый объем памяти. Этот подход особенно полезен для задач, где доступ к оперативной памяти ограничен, например, при работе с миллиардами векторов в рекомендательных системах или медицинской диагностике. Таким образом, использование PQ позволяет FAISS эффективно работать с огромными наборами данных, сохраняя высокую скорость и точность поиска.

Сравнительные тесты производительности FAISS на CPU и GPU демонстрируют значительное преимущество использования графических процессоров. Например, на датасете YFCC100M, состоящем из 95 миллионов изображений, FAISS смог построить k-NN граф с точностью 0.8 за 35 минут на четырех GPU Titan X [\[19](https://engineering.fb.com/2017/03/29/data-infrastructure/faiss-a-library-for-efficient-similarity-search/)]. Аналогичная задача на CPU заняла бы значительно больше времени, что делает использование GPU критически важным для задач реального времени. Кроме того, автоматический механизм настройки параметров в FAISS позволяет находить оптимальные настройки для конкретных задач, обеспечивая высокую производительность даже при изменении условий работы.

На основе проведенного анализа можно сделать вывод о важности поддержки GPU для оптимизации производительности FAISS. Использование графических процессоров позволяет значительно ускорить построение индексов и выполнение запросов, что критично для работы с большими объемами данных. Хотя HNSWLib остается эффективным решением для задач реального времени с ограниченным объемом данных, его отсутствие поддержки GPU ограничивает его применимость для крупномасштабных проектов. Таким образом, выбор между HNSWLib и FAISS должен основываться на анализе требований к производительности, доступным аппаратным ресурсам и размеру обрабатываемых данных.

**Оптимизация производительности библиотек HNSWLib и FAISS для эффективного поиска векторов**

В современных приложениях, связанных с обработкой больших объемов данных,

таких как рекомендательные системы, поиск изображений и семантический анализ текста, важным аспектом является оптимизация алгоритмов для быстрого и точного поиска. Одними из наиболее популярных решений в этой области являются библиотеки HNSWLib и FAISS. В данном разделе рассматриваются ключевые подходы к настройке параметров этих библиотек для достижения максимальной производительности при сохранении высокой точности результатов.

Для HNSWLib основными параметрами, влияющими на баланс между скоростью и точностью, являются M (количество соседей, которые хранятся для каждого узла) и ef\_construction (размер списка кандидатов при построении графа). Рекомендуется начинать с базовых значений M=16 и ef\_construction=200, что позволяет достичь recall ≥ 0.95 для наборов данных размером до нескольких миллионов векторов [ [6](https://stackoverflow.com/questions/65379421/hnswlib-parameters-for-large-datasets)]. Однако при работе с более крупными датасетами может возникнуть необходимость увеличения ef\_construction до значений выше 1000, что потребует также корректировки M для поддержания высокой производительности. Например, тестирование показывает, что при наборах данных более

1 миллиона векторов снижение recall с 0.9 до 0.7 может быть компенсировано итеративной настройкой ef\_construction и последующим пересозданием индекса с новыми параметрами. Важно учитывать, что время построения индекса значительно возрастает с увеличением M и ef\_construction, достигая нескольких часов для больших датасетов.

FAISS предлагает широкий спектр методов для оптимизации производительности, особенно в условиях работы с огромными объемами данных. Для снижения задержек рекомендуется хранить предварительно построенные индексы в облачных репозиториях, таких как Hugging Face Hub. Это позволяет загружать их по мере необходимости и использовать для быстрого доступа к данным[ \[4](https://huggingface.co/learn/cookbook/en/faiss_with_hf_datasets_and_clip)]. Примером может служить использование API Hugging Face для загрузки индекса 'embeddings.faiss' и его последующего применения для выполнения запросов, например, связанных с поиском по описанию или изображению.

При тонкой настройке параметров FAISS особое внимание уделяется таким значениям, как nprobe (количество проверяемых ячеек) и nlist (число центроидов в IVF-индексе). Увеличение nprobe повышает точность поиска за счет более глубокого анализа данных, но замедляет выполнение запросов. Оптимальное соотношение между этими параметрами зависит от задачи и характеристик данных. Например, нормализация векторов перед индексацией может улучшить качество результатов при использовании метрики косинусной близости [\[22](https://programmer.ie/post/faiss/)]. Кроме того, применение методов, таких как Principal Component Analysis (PCA), перед построением индекса способствует улучшению качества эмбеддингов.

Одним из значимых преимуществ FAISS является автоматический механизм настройки параметров, который помогает находить оптимальные конфигурации для конкретных

задач. Исследования показывают, что на датасете Deep1B с миллиардом 128-мерных векторов FAISS достигает точности 40% при времени запроса менее 2 мс на один вектор, что значительно превышает результаты предыдущих решений [\[19](https://engineering.fb.com/2017/03/29/data-infrastructure/faiss-a-library-for-efficient-similarity-search/)]. Этот механизм позволяет минимизировать ручную настройку и обеспечивает высокую производительность даже при работе с разнородными типами данных, такими как текстовые и визуальные эмбеддинги.

Таким образом, правильная конфигурация параметров и выбор аппаратного обеспечения играют ключевую роль в достижении оптимальной производительности HNSWLib и FAISS. GPU-ускорение, например, использование современных видеокарт Nvidia A100, может существенно сократить время выполнения запросов благодаря SIMD-оптимизации и специализированным алгоритмам k-selection[ \[19](https://engineering.fb.com/2017/03/29/data-infrastructure/faiss-a-library-for-efficient-similarity-search/)]. Тем не менее, для задач с нерегулярными вычислениями, такими как обход графов, эффективность GPU может быть ниже, чем CPU. В будущем исследования могут сосредоточиться на разработке гибридных подходов, сочетающих возможности обоих типов оборудования для дальнейшего повышения производительности.

**Сравнение HNSWLib и FAISS для задачи поиска по эмбеддингам в системе video-rag**

Ниже представлена сравнительная таблица характеристик HNSWLib и FAISS, основанная на собранных данных. Она поможет понять, как эти библиотеки подходят для работы с большими наборами данных и мультимодальными запросами.



|**Характеристика**|**HNSWLib**|**FAISS**|
| - | - | - |
|**Поддержка GPU**|Только CPU|<p>Поддерживает GPU, что значительно ускоряет обработку</p><p>больших данных [10[\]](https://zilliz.com/blog/faiss-vs-hnswlib-choosing-the-right-tool-for-vector-search)</p>|
|**Масштабируемость**|Лучше подходит для наборов данных, помещающихся в RAM|Может работать с миллиардами векторов благодаря использованию методов IVF и PQ [[20](https://github.com/facebookresearch/faiss/wiki)]|
|<p>**Оптимизация для**</p><p>**CPU**</p>|Высокая производительность на CPU при работе с небольшими и средними наборами данных|<p>Производительность на CPU ниже по сравнению с HNSWLib, особенно на больших наборах</p><p>данных [[17\]](https://terencezl.github.io/blog/2022/09/28/kids-use-hnswlib/)</p>|
|**Методы индексации**|<p>Использует графовый</p><p>подход (HNSW)</p>|Предоставляет гибкие методы индексации, такие как IVF и PQ [[21](https://www.pingcap.com/article/mastering-faiss-vector-database-a-beginners-handbook/)]|
|**Точность поиска**|Точность может снижаться на больших датасетах (>1M векторов)|Позволяет тонко настраивать точность через параметры nprobe и другие методы оптимизации [\[22](https://programmer.ie/post/faiss/)]|
|**Поддержка мультимодальных данных**|Ограниченная; требует ручной настройки параметров M и ef\_construction [\[6](https://stackoverflow.com/questions/65379421/hnswlib-parameters-for-large-datasets)]|<p>Интегрируется с моделями transformers и CLIP,</p><p>поддерживая текстовые и визуальные эмбеддинги[ \[4](https://huggingface.co/learn/cookbook/en/faiss_with_hf_datasets_and_clip)]</p>|
|<p>**Время построения**</p><p>**индекса**</p>|<p>Быстрее при добавлении данных (например, 3.1 часа против 6 часов для 37.9M</p><p>векторов)</p>|<p>Длительное время построения индекса для больших наборов</p><p>данных [[17\]](https://terencezl.github.io/blog/2022/09/28/kids-use-hnswlib/)</p>|
|**Управление память**|<p>Все данные хранятся в **ю**</p><p>оперативной памяти</p>|<p>Поддерживает методы сжатия данных, такие как PQ, для</p><p>эффективного использования</p><p>памяти [\[21](https://www.pingcap.com/article/mastering-faiss-vector-database-a-beginners-handbook/)]</p>|

Из таблицы видно, что HNSWLib демонстрирует лучшую производительность на CPU и

более быстрое добавление данных, что делает его предпочтительным выбором для задач реального времени с небольшими или средними наборами данных. Однако FAISS

предлагает больше возможностей для масштабирования и работы с мультимодальными данными благодаря поддержке GPU и гибким методам индексации. Для системы video-rag, где могут потребоваться обработка больших объемов данных и работа с комбинированными текстовыми и визуальными эмбеддингами, FAISS представляется более подходящим решением.

**Заключение**

Основываясь на проведенном анализе, можно сделать вывод о том, что выбор между HNSWLib и FAISS должен основываться на специфике задачи, требуемой производительности и доступных аппаратных ресурсах. HNSWLib демонстрирует превосходную производительность на CPU для небольших и средних наборов данных, обеспечивая быстрый поиск с минимальными [задержками \[10](https://zilliz.com/blog/faiss-vs-hnswlib-choosing-the-right-tool-for-vector-search)]. Однако его ограничения в плане использования RAM и сложности работы с большими объемами данных делают его менее подходящим для крупномасштабных проектов. В частности, HNSWLib сталкивается с проблемами масштабируемости при работе с высокоразмерными данными, что ограничивает его применимость для задач, требующих обработки миллиардов векторов[ \[10](https://zilliz.com/blog/faiss-vs-hnswlib-choosing-the-right-tool-for-vector-search)].

В то же время, FAISS предлагает множество настраиваемых параметров для работы с большими массивами данных, таких как IVF (инвертированный файловый индекс) и PQ (квантизация произведения), позволяя оптимизировать использование памяти и повышать эффективность поиска [\[10](https://zilliz.com/blog/faiss-vs-hnswlib-choosing-the-right-tool-for-vector-search)]. Поддержка GPU значительно ускоряет процесс поиска, особенно для задач, требующих обработки миллиардов векторов. Например, использование GPU может сократить задержки до менее 20 мс при работе с индексами размером более 10 миллионов векторов [\[18](https://www.langchain.ca/blog/mastering-faiss-the-ultimate-user-guide/)]. 

Таким образом, для задач, требующих обработки огромных объемов данных и

интеграции мультимодальных эмбеддингов, таких как в системе video-rag, FAISS представляет собой более предпочтительное решение. Его гибкость в индексации, поддержка GPU и методы сжатия данных обеспечивают высокую производительность и точность поиска, что критично для работы с большими наборами данных. Тем не менее, HNSWLib остается ценным инструментом для задач реального времени с ограниченными объемами данных, где основной приоритет отдается минимизации задержек без использования GPU.

Исследование также подчеркивает важность предварительной обработки данных и тонкой настройки параметров для достижения оптимального баланса между скоростью и точностью. Например, для HNSWLib рекомендуется начинать с базовых значений M=16 и ef\_construction=200, которые могут быть скорректированы в зависимости от требований задачи [\[6](https://stackoverflow.com/questions/65379421/hnswlib-parameters-for-large-datasets)]. В случае FAISS, автоматический механизм настройки параметров упрощает оптимизацию производительности, особенно при работе с разнородными типами данных, такими как текстовые и визуальные [эмбеддинги \[19](https://engineering.fb.com/2017/03/29/data-infrastructure/faiss-a-library-for-efficient-similarity-search/)].

Наконец, важно отметить ограничения текущих подходов, таких как снижение точности при работе с out-of-distribution данными или необходимость аппаратного ускорения для достижения максимальной производительности. Эти факторы должны учитываться при проектировании систем, работающих с большими объемами данных и мультимодальными запросами. Для будущих исследований рекомендуется сосредоточиться на разработке гибридных решений, сочетающих преимущества CPU и GPU, а также на совершенствовании методов сжатия данных и индексации для повышения масштабируемости и эффективности [\[8](https://arxiv.org/html/2401.08281v3)].

Таким образом, выбор между HNSWLib и FAISS зависит от конкретных требований проекта. Для системы video-rag, где требуется обработка больших объемов данных и работа с комбинированными текстовыми и визуальными эмбеддингами, FAISS представляется более подходящим решением благодаря своей масштабируемости, поддержке GPU и гибкости в интеграции с современными моделями, такими как CLIP и [ImageBind](https://huggingface.co/learn/cookbook/en/faiss_with_hf_datasets_and_clip) [[4](https://huggingface.co/learn/cookbook/en/faiss_with_hf_datasets_and_clip)]. Однако для задач реального времени с ограниченными ресурсами HNSWLib остается привлекательным вариантом благодаря своей высокой скорости на CPU и простоте использования.
